"""Optimization package for hyperparameter tuning and model optimization."""

from .distillation_utils import (
    analyze_distillation_impact,
    compare_distillation_temperatures,
    create_ensemble_student,
    create_student_model,
    distill_knowledge,
    get_default_distillation_config,
    get_feature_matching_config,
    get_high_temperature_config,
    get_progressive_distillation_config,
    validate_distilled_model,
)
from .hyperparameter_tuning import (
    HyperparameterOptimizer,
    OptimizationConfig,
    OptimizationResult,
    get_fast_optimization_config,
    get_production_optimization_config,
    optimize_all_models,
)
from .knowledge_distillation import (
    AttentionTransferLoss,
    DistillationConfig,
    DistillationLoss,
    DistillationResult,
    FeatureMatchingLoss,
    KnowledgeDistiller,
)
from .model_pruning import (
    GradualPruner,
    MagnitudePruner,
    ModelPruner,
    PruningConfig,
    PruningResult,
    StructuredPruner,
    analyze_pruning_impact,
    compare_pruning_methods,
    get_default_pruning_config,
    get_gradual_pruning_config,
    get_magnitude_pruning_config,
    get_structured_pruning_config,
    prune_model,
)
from .model_quantization import (
    ModelQuantizer,
    PostTrainingDynamicQuantizer,
    PostTrainingStaticQuantizer,
    QATQuantizer,
    QuantizableModel,
    QuantizationConfig,
    QuantizationResult,
)
from .quantization_utils import (
    analyze_quantization_impact,
    benchmark_quantized_model,
    compare_quantization_methods,
    get_default_quantization_config,
    get_dynamic_quantization_config,
    get_mobile_quantization_config,
    get_qat_config,
    get_static_quantization_config,
    quantize_model,
    validate_quantized_model_accuracy,
)

__all__ = [
    "HyperparameterOptimizer",
    "OptimizationConfig",
    "OptimizationResult",
    "optimize_all_models",
    "get_fast_optimization_config",
    "get_production_optimization_config",
    "ModelPruner",
    "PruningConfig",
    "PruningResult",
    "MagnitudePruner",
    "StructuredPruner",
    "GradualPruner",
    "prune_model",
    "get_default_pruning_config",
    "get_magnitude_pruning_config",
    "get_structured_pruning_config",
    "get_gradual_pruning_config",
    "analyze_pruning_impact",
    "compare_pruning_methods",
    "ModelQuantizer",
    "QuantizationConfig",
    "QuantizationResult",
    "QATQuantizer",
    "PostTrainingStaticQuantizer",
    "PostTrainingDynamicQuantizer",
    "QuantizableModel",
    "quantize_model",
    "get_default_quantization_config",
    "get_qat_config",
    "get_static_quantization_config",
    "get_dynamic_quantization_config",
    "get_mobile_quantization_config",
    "analyze_quantization_impact",
    "compare_quantization_methods",
    "benchmark_quantized_model",
    "validate_quantized_model_accuracy",
    "KnowledgeDistiller",
    "DistillationConfig",
    "DistillationResult",
    "DistillationLoss",
    "FeatureMatchingLoss",
    "AttentionTransferLoss",
    "distill_knowledge",
    "get_default_distillation_config",
    "get_high_temperature_config",
    "get_progressive_distillation_config",
    "get_feature_matching_config",
    "create_student_model",
    "analyze_distillation_impact",
    "compare_distillation_temperatures",
    "validate_distilled_model",
    "create_ensemble_student",
]
